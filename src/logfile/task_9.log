/dss/dsshome1/04/di35van/miniconda3/envs/vim/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:186: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.
  'approximations.', UserWarning)
INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_716e2202694bcd73235bf75d865d3cf3 NOW.
['hyperparameter_tuning_fit.py', '42', '4', '200', '176.82633222346016', '0.1', '4284064', '200', '9']
------------------------------------------------------------
EXPERIMENTAL ALGORITHM:
  This procedure has not been thoroughly tested and may be unstable
  or buggy. The interface is subject to change.
------------------------------------------------------------



Gradient evaluation took 3.73572 seconds
1000 transitions using 10 leapfrog steps per transition would take 37357.2 seconds.
Adjust your expectations accordingly!


Begin eta adaptation.
Iteration:   1 / 250 [  0%]  (Adaptation)
Iteration:  50 / 250 [ 20%]  (Adaptation)
Iteration: 100 / 250 [ 40%]  (Adaptation)
Iteration: 150 / 250 [ 60%]  (Adaptation)
Iteration: 200 / 250 [ 80%]  (Adaptation)
Iteration: 250 / 250 [100%]  (Adaptation)
Success! Found best value [eta = 0.1].

Begin stochastic gradient ascent.
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes 
    50     -3754003.486             1.000            1.000
   100     -2447232.226             0.767            1.000
   150     -1911272.219             0.605            0.534
   200     -1646977.091             0.494            0.534
   250     -1500280.087             0.268            0.280
   300     -1416423.765             0.149            0.160
   350     -1358733.739             0.090            0.098
   400     -1318927.073             0.057            0.059
   450     -1290041.752             0.039            0.042
   500     -1265163.948             0.029            0.030
   550     -1244898.048             0.022            0.022
   600     -1226892.950             0.018            0.020
   650     -1210893.073             0.016            0.016
   700     -1196158.750             0.014            0.015
   750     -1183702.486             0.013            0.013
   800     -1171095.710             0.012            0.012
   850     -1160311.588             0.011            0.011
   900     -1149984.838             0.010            0.011   MEAN ELBO CONVERGED

Drawing a sample of size 200 from the approximate posterior... 
COMPLETED.
WARNING:pystan:Automatic Differentiation Variational Inference (ADVI) is an EXPERIMENTAL ALGORITHM.
WARNING:pystan:ADVI samples may be found on the filesystem in the file `/dss/dsshome1/04/di35van/Workspace/vi-midas/results/hyperparameter/4284064_9_nb_sample.csv`
/dss/dsshome1/04/di35van/Workspace/vi-midas/utils/vb_stan.py:25: RuntimeWarning: invalid value encountered in multiply
  params = OrderedDict([(name, np.nan * np.empty((n, ) + tuple(shape))) for name, shape in param_shapes.items()])
/dss/dsshome1/04/di35van/Workspace/vi-midas/utils/vb_stan.py:57: RuntimeWarning: invalid value encountered in multiply
  params = OrderedDict([(name, np.nan * np.empty(shape)) for name, shape in param_shapes.items()])
[42, 4, 200.0, 176.82633222346016, 0.1, 4284064, 200, 9]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
