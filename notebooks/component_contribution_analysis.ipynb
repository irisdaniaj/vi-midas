{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component contribution analysis\n",
    "\n",
    "From the hyperparameter tuning step, we have selected a set of parameters ($\\lambda$,  $ \\vartheta$, k) with largest **LLPD$_o$**.  \n",
    "\n",
    "Here we aim to evaluate the contribution of each of the components in the generative model (MEM). The generative model for the ocean microbiome data for the microbial abundance data consists of **geochemical component**, **spatio-temporal components indicating geographical location, ocean depth and time** and **species-species interaction component**. To understand their  contribution in the MEM, we drop each of the specific component in the generative model, estimate the variational posterior and then evaluate the model performance in terms of the **out of sample log-likelihood predictive density (LLPD$_o$)**.\n",
    "\n",
    "\n",
    "Steps of the analysis\n",
    " + Define component excluded generative model\n",
    " + Python script for the variational posterior estimation: **component_contribution_fit.py**\n",
    " + Script to call component excluded generative model  \n",
    " + Evaluate the model in terms of the **LLPD$_o$**\n",
    "\n",
    " \n",
    "#### Component excluded generative model\n",
    "We have defined the component excluded stan model (see stan_model folder) in the following files:\n",
    " + **NB_microbe_ppc.stan** : Full model [Model = 0]\n",
    " + **NB_microbe_ppc-1.stan** : Province component dropped  [Model = 1]\n",
    " + **NB_microbe_ppc-2.stan** : Biome component dropped  [Model = 2]\n",
    " + **NB_microbe_ppc-3.stan** : Quarter/Time component dropped  [Model = 3]\n",
    " + **NB_microbe_ppc-G.stan** : Geochemical component dropped  [Model = 4]\n",
    " + **NB_microbe_ppc_nointer.stan** : Species-species interaction component dropped  [Model = 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script to evaluate the model\n",
    "For the chosen set of hyperparameters, we compute the variational posterior of each the **component excluded generative model** for **twenty** different initialization. We have saved the command calling **component_contribution_fit.py** for each of the  **component excluded generative model** in the file **mem_component_contribution** (see the python cript below to generate the file).\n",
    "\n",
    "A line in the file **mem_component_contribution** calls the python script **component_contribution_fit.py** for a given choice of the parameters. \n",
    "\n",
    "*module purge ; module load slurm gcc python3 ; OMP_NUM_THREADS=1 python3 component_contribution_fit.py 100.0 0.219 0.06503 0.1 200 1 0 1.0 > logfile/1.log 2>&1*\n",
    "\n",
    "Input parameters for a setting includes **latent rank (k),  $\\lambda$,  $\\vartheta$, test sample proportion, variational posterior sample size,  sub-settings unique ID (1-20), model type  and setting seed**. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "random.seed(123)\n",
    "best_model_param = pkl.load(open('selected_hyperparam', 'rb'))\n",
    "best_model_param = [best_model_param['k'].values[0],\\\n",
    "                    best_model_param['lambda'].values[0],\\\n",
    "                    best_model_param['upsilon'].values[0]]\n",
    "h_prop = 0.1    # holdout proportion of test sample data to compute LLPD\n",
    "nsample_o = 200 # number of posterior sample \n",
    "\n",
    "# command for server\n",
    "command_server = 'module purge ; module load slurm gcc python3 ; OMP_NUM_THREADS=1 python3 component_contribution_fit.py '\n",
    "setting = []\n",
    "seedid = 0. ;\n",
    "\n",
    "# generates setting and corresponding command script\n",
    "# mtype: variable for 6 model type including full model \n",
    "for mtype in range(6):\n",
    "    for sid in range(20):\n",
    "        seedid = seedid + 1.\n",
    "        a = command_server + ' '.join(list(map(str,   best_model_param + [h_prop, nsample_o, sid + 1,mtype, seedid] )))    \n",
    "        setting.append((a + ' > logfile/{}.log 2>&1').format(int(seedid)))\n",
    "\n",
    "# save command \n",
    "fname = \"mem_component_contribution\"\n",
    "with open(fname, 'w') as filehandle:\n",
    "    filehandle.writelines(\"%s\\n\" % place for place in setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Parameter estimation \n",
    "We run the script on server using the command:\n",
    "*sbatch -N [#node] -p [#partition] disBatch.py -t [#task on each node] [script_file]*\n",
    "Example: *sbatch -N 10 -p ccm disBatch.py -t 25 mem_component_contribution*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Model output analysis\n",
    "Evaluate each of the **component excluded generative model** based on the $LLPD_o$. Let us consider our model output is saved in the folder **CContribution**. To compare the model, we load the output file and compute the $LLPD_o$ for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load python module \n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file name \n",
    "# We have save the output in [CContribution] folder\n",
    "fname_o = glob.glob('../results/component/models/*model_nb_cvtest.pkl') \n",
    "out = np.empty((len(fname_o),7))\n",
    "mtype_file = np.argsort([int(x.split('/')[1].split('_')[1].split('.')[0]) for x in fname_o])\n",
    "fname_o = [fname_o[i] for i in mtype_file]\n",
    "#fname_o[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model output and compute LLPD\n",
    "for i in range(len(fname_o)):\n",
    "    if ((i%20) == 0):\n",
    "        print(i)\n",
    "    [holdout_mask, Yte_sample, llpd, n_test, l,m_seed,sp_mean,\\\n",
    "                 sp_var, h_prop, uid, nsample_o, Yte_fit,\\\n",
    "                 cv_test,Y, muest, Yte_cv, Yte_lpmf, kl_comp] = pkl.load(open(fname_o[i], \"rb\"))\n",
    "    se_index  = holdout_mask == 1. \n",
    "\n",
    "    # LLPD compute \n",
    "    temp_ll = cv_test[se_index]\n",
    "    temp_ll = np.mean(temp_ll)  \n",
    "    mtype = fname_o[i].split('/')[1].split('_')[1]\n",
    "    mtype = int(mtype.split('.')[0])\n",
    "    error = np.mean(np.power(Y - muest,2)[se_index])\n",
    "    out[i] = [i, l, sp_mean,sp_var,  temp_ll,uid, mtype]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>rank</th>\n",
       "      <th>lambda</th>\n",
       "      <th>upsilon</th>\n",
       "      <th>llpd</th>\n",
       "      <th>uid</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Index, rank, lambda, upsilon, llpd, uid, Model]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl.dump(out, open('comparison_model', \"wb\"))  # save output \n",
    "out = pkl.load(open('comparison_model', \"rb\"))\n",
    "out = pd.DataFrame(data=out)\n",
    "out.columns = ['Index','rank','lambda','upsilon','llpd','uid','Model']\n",
    "out.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Our analysis suggest that the model 0, i.e., MEM is best with highest out of sample LLPD$_o$.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">llpd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Model, ), (llpd, mean), (llpd, std)]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.groupby(['Model'], as_index=False).agg({'llpd':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "\\textbf{Empty DataFrame\n",
      "Columns: Int64Index([], dtype='int64')\n",
      "Index: Index(['Model', 'llpd'], dtype='object')} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_sub = out.groupby(['Model'], as_index=False).mean()[['Model','llpd']].transpose()\n",
    "print(out_sub.to_latex(float_format=\"%.4f\", bold_rows = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2275984/2231883557.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "l,m_seed,sp_mean, sp_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
