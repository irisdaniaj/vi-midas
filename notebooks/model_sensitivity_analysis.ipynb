{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Sensitivity Analysis\n",
    "Maximizing the ELBO is a non-convex optimization problem. The parameters estimate are sensitive to the choice of their initial estimates. Hence, we further evaluate the chosen set of hyperparameters for 50 random initialization and then select the best model out of it. \n",
    "\n",
    "Stages of the Analysis\n",
    " + Python script for variational posterior computation: **model_sensitivity_fit.py**\n",
    " + Script to evaluate the model for 50 random initialization: **mem_model_sensitivity**\n",
    " + Analysis of the output based on in sample $LLPD$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script to evaluate the model\n",
    "We have saved the command for calling the python script for parameter estimation in the file **mem_model_sensitivity**.\n",
    "\n",
    "A line in the file **mem_model_sensitivity** calls the python script **model_sensitivity_fit.py** for a given choice of the parameters. \n",
    "\n",
    "*module purge ; module load slurm gcc python3 ; omp_num_threads=1 python3 model_sensitivity_fit.py 100.0 50 0.219 0.06503 0.0 50 200 > logfile/50.log 2>&1*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "outx = pickle.load(open('selected_hyperparam', \"rb\"))\n",
    "hyperparam = outx.iloc[:,range(2,5)]\n",
    "ninit = 50      # number of initialization \n",
    "h_prop = 0.0    # holdout proportion of test sample data to compute LLPD\n",
    "nsample_o = 200 # number of posterior sample \n",
    "\n",
    "command_server = 'module purge ; module load slurm gcc python3 ; omp_num_threads=1 python3 model_sensitivity_fit.py '\n",
    "setting = []; sx = []\n",
    "for hset in range(hyperparam.shape[0]):  \n",
    "   for uid in range(ninit):\n",
    "       [l,s_m, s_v]  = hyperparam.iloc[hset,:]; \n",
    "       sed = ninit*(hset + 1) + uid# (2*uid + 101.)*(2*hset + 101.)\n",
    "       sx.append(sed)\n",
    "       a = command_server + ' '.join(list(map(str, [l,sed,s_m,s_v, h_prop, int(sed), nsample_o])))    \n",
    "       setting.append((a + ' > logfile/{}.log 2>&1').format(int(sed)))\n",
    "       \n",
    "fname = \"mem_model_sensitivity\"\n",
    "with open(fname, 'w') as filehandle:\n",
    "   filehandle.writelines(\"%s\\n\" % place for place in setting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter estimation \n",
    "We run the script on server using the command:\n",
    "*sbatch -N [#node] -p [#partition] disBatch.py -t [#task on each node] [script_file]*\n",
    "\n",
    "Example: *sbatch -N 2 -p ccm disBatch.py -t 25 mem_model_sensitivity*\n",
    "\n",
    "\n",
    "\n",
    "#### Model output analysis\n",
    "Let us consider out model output is saved in the folder **MMSens**. We load each of the output file, compute the $LLPD$ on  full data and select the model with the largest LLPD. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in: ../results/results_op/sensitivity/models/\n",
      "Loaded files: ['../results/results_op/sensitivity/models/30_65_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_53_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_56_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_57_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_52_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_63_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_72_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_69_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_73_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_60_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_67_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_62_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_68_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_66_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_50_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_54_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_51_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_71_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_61_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_70_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_59_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_64_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_58_model_nb_cvtest.pkl', '../results/results_op/sensitivity/models/30_55_model_nb_cvtest.pkl']\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hiplot as hip\n",
    "import os \n",
    "import copy \n",
    "\n",
    "# Ensure inline plotting for Jupyter Notebook (remove if not needed)\n",
    "%matplotlib inline  \n",
    "\n",
    "# Define the folder containing the model files\n",
    "fname_o = glob.glob('../results/results_op/sensitivity/models/*model_nb_cvtest.pkl') \n",
    "\n",
    "# Filter out files that contain \"sample\"\n",
    "fname_o = [file for file in fname_o if 'sample' not in file]\n",
    "\n",
    "# Debugging and verification\n",
    "print(\"Looking for files in: ../results/results_op/sensitivity/models/\")\n",
    "print(\"Loaded files:\", fname_o)  # Check if the file is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the relative file paths\n",
    "#fname_o = glob.glob('../results/hyperparameter/*model_nb_cvtest.pkl')\n",
    "\n",
    "# Iterate through each .pkl file and inspect its content ech .pkl should have 12 elements \n",
    "for file in fname_o:\n",
    "    print(f\"Inspecting file: {os.path.relpath(file)}\")\n",
    "    try:\n",
    "        with open(file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Check if the data is iterable (e.g., list, tuple, dict)\n",
    "        if isinstance(data, (list, tuple)):\n",
    "            print(f\"File contains a {type(data).__name__} with {len(data)} elements.\")\n",
    "            for i, element in enumerate(data):\n",
    "                print(f\"  Element {i}: Type={type(element)}\")\n",
    "        elif isinstance(data, dict):\n",
    "            print(f\"File contains a dictionary with {len(data)} keys.\")\n",
    "            for key, value in data.items():\n",
    "                print(f\"  Key='{key}': Type={type(value)}\")\n",
    "        else:\n",
    "            print(f\"File contains a single object of type {type(data).__name__}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading {file}: {e}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Extract model output\n",
    "out = np.empty((len(fname_o),6))\n",
    "for i in range(0,len(fname_o)):\n",
    "    if (i%10) ==0:\n",
    "        print(i)\n",
    "    [holdout_mask, llpd, n_test, l,m_seed,sp_mean,\\\n",
    "                 sp_var, h_prop, uid, nsample_o,\\\n",
    "                 Yte_fit, cv_test] = pickle.load(open(fname_o[i], \"rb\"))\n",
    "    out[i] = [i, l, sp_mean,sp_var,  np.mean(cv_test), np.mean(Yte_fit)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rank</th>\n",
       "      <th>lambda</th>\n",
       "      <th>upsilon</th>\n",
       "      <th>llpd</th>\n",
       "      <th>Log-likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.240068</td>\n",
       "      <td>-3.262017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.243401</td>\n",
       "      <td>-3.263559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.242221</td>\n",
       "      <td>-3.264069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.240078</td>\n",
       "      <td>-3.260899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.241571</td>\n",
       "      <td>-3.262434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.242202</td>\n",
       "      <td>-3.262935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.243495</td>\n",
       "      <td>-3.264110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.243118</td>\n",
       "      <td>-3.264178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.241822</td>\n",
       "      <td>-3.261233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.243269</td>\n",
       "      <td>-3.263314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   rank    lambda   upsilon      llpd  Log-likelihood\n",
       "0    0.0  100.0  0.060596  0.040816 -3.240068       -3.262017\n",
       "1    1.0  100.0  0.060596  0.040816 -3.243401       -3.263559\n",
       "2    2.0  100.0  0.060596  0.040816 -3.242221       -3.264069\n",
       "3    3.0  100.0  0.060596  0.040816 -3.240078       -3.260899\n",
       "4    4.0  100.0  0.060596  0.040816 -3.241571       -3.262434\n",
       "5    5.0  100.0  0.060596  0.040816 -3.242202       -3.262935\n",
       "6    6.0  100.0  0.060596  0.040816 -3.243495       -3.264110\n",
       "7    7.0  100.0  0.060596  0.040816 -3.243118       -3.264178\n",
       "8    8.0  100.0  0.060596  0.040816 -3.241822       -3.261233\n",
       "9    9.0  100.0  0.060596  0.040816 -3.243269       -3.263314"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(out, open('best_model_selected.pkl','wb'))  # save output \n",
    "out = pickle.load(open('best_model_selected.pkl','rb'))\n",
    "outx = pd.DataFrame(out)\n",
    "outx.columns = ['index','rank','lambda', 'upsilon', 'llpd' ,'Log-likelihood']\n",
    "outx.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../results/results_op/sensitivity/models/30_68_model_nb_cvtest.pkl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the file name and model output from the best model \n",
    "best_setting = outx[outx.iloc[:,4] == outx.iloc[:,4].max()]\n",
    "i = int(best_setting.loc[:,'index'])\n",
    "fname_o[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rank</th>\n",
       "      <th>lambda</th>\n",
       "      <th>upsilon</th>\n",
       "      <th>llpd</th>\n",
       "      <th>Log-likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-3.239599</td>\n",
       "      <td>-3.259148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   rank    lambda   upsilon      llpd  Log-likelihood\n",
       "12   12.0  100.0  0.060596  0.040816 -3.239599       -3.259148"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Our analysis suggest that MEM with seed 66 is most appropriate with highest full data LLPD.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
