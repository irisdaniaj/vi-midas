{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Sensitivity Analysis\n",
    "Maximizing the ELBO is a non-convex optimization problem. The parameters estimate are sensitive to the choice of their initial estimates. Hence, we further evaluate the chosen set of hyperparameters for 50 random initialization and then select the best model out of it. \n",
    "\n",
    "Stages of the Analysis\n",
    " + Python script for variational posterior computation: **model_sensitivity_fit.py**\n",
    " + Script to evaluate the model for 50 random initialization: **mem_model_sensitivity**\n",
    " + Analysis of the output based on in sample $LLPD$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script to evaluate the model\n",
    "We have saved the command for calling the python script for parameter estimation in the file **mem_model_sensitivity**.\n",
    "\n",
    "A line in the file **mem_model_sensitivity** calls the python script **model_sensitivity_fit.py** for a given choice of the parameters. \n",
    "\n",
    "*module purge ; module load slurm gcc python3 ; omp_num_threads=1 python3 model_sensitivity_fit.py 100.0 50 0.219 0.06503 0.0 50 200 > logfile/50.log 2>&1*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "outx = pickle.load(open('selected_hyperparam', \"rb\"))\n",
    "hyperparam = outx.iloc[:,range(2,5)]\n",
    "ninit = 50      # number of initialization \n",
    "h_prop = 0.0    # holdout proportion of test sample data to compute LLPD\n",
    "nsample_o = 200 # number of posterior sample \n",
    "\n",
    "command_server = 'module purge ; module load slurm gcc python3 ; omp_num_threads=1 python3 model_sensitivity_fit.py '\n",
    "setting = []; sx = []\n",
    "for hset in range(hyperparam.shape[0]):  \n",
    "   for uid in range(ninit):\n",
    "       [l,s_m, s_v]  = hyperparam.iloc[hset,:]; \n",
    "       sed = ninit*(hset + 1) + uid# (2*uid + 101.)*(2*hset + 101.)\n",
    "       sx.append(sed)\n",
    "       a = command_server + ' '.join(list(map(str, [l,sed,s_m,s_v, h_prop, int(sed), nsample_o])))    \n",
    "       setting.append((a + ' > logfile/{}.log 2>&1').format(int(sed)))\n",
    "       \n",
    "fname = \"mem_model_sensitivity\"\n",
    "with open(fname, 'w') as filehandle:\n",
    "   filehandle.writelines(\"%s\\n\" % place for place in setting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter estimation \n",
    "We run the script on server using the command:\n",
    "*sbatch -N [#node] -p [#partition] disBatch.py -t [#task on each node] [script_file]*\n",
    "\n",
    "Example: *sbatch -N 2 -p ccm disBatch.py -t 25 mem_model_sensitivity*\n",
    "\n",
    "\n",
    "\n",
    "#### Model output analysis\n",
    "Let us consider out model output is saved in the folder **MMSens**. We load each of the output file, compute the $LLPD$ on  full data and select the model with the largest LLPD. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load module \n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Get file name \n",
    "folname = 'MMSens/'\n",
    "fname_o = glob.glob(folname+'*model_nb_cvtest.pkl')\n",
    "fname_x = []\n",
    "for tem in fname_o:\n",
    "    if tem.find('sample') < 0.:\n",
    "        fname_x.append(tem)\n",
    "fname_o = fname_x    \n",
    "#fname_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hiplot as hip\n",
    "import os \n",
    "import copy \n",
    "%matplotlib inline\n",
    "## We have saved the variational posterior estimated from hyperparameter tuning in [HPcheck] folder \n",
    "#print(\"Current working directory:\", os.getcwd())  # Check where the script is running from\n",
    "fname_o = glob.glob('../results/sensitivity/models/*model_nb_cvtest.pkl') \n",
    "print(\"Looking for files in:\", fname_o)\n",
    "print(\"Loaded files:\", fname_o) #Check if the file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the relative file paths\n",
    "#fname_o = glob.glob('../results/hyperparameter/*model_nb_cvtest.pkl')\n",
    "\n",
    "# Iterate through each .pkl file and inspect its content ech .pkl should have 13 elements \n",
    "for file in fname_o:\n",
    "    print(f\"Inspecting file: {os.path.relpath(file)}\")\n",
    "    try:\n",
    "        with open(file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Check if the data is iterable (e.g., list, tuple, dict)\n",
    "        if isinstance(data, (list, tuple)):\n",
    "            print(f\"File contains a {type(data).__name__} with {len(data)} elements.\")\n",
    "            for i, element in enumerate(data):\n",
    "                print(f\"  Element {i}: Type={type(element)}\")\n",
    "        elif isinstance(data, dict):\n",
    "            print(f\"File contains a dictionary with {len(data)} keys.\")\n",
    "            for key, value in data.items():\n",
    "                print(f\"  Key='{key}': Type={type(value)}\")\n",
    "        else:\n",
    "            print(f\"File contains a single object of type {type(data).__name__}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading {file}: {e}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model output\n",
    "out = np.empty((len(fname_o),6))\n",
    "for i in range(0,len(fname_o)):\n",
    "    if (i%10) ==0:\n",
    "        print(i)\n",
    "    [holdout_mask, llpd, n_test, l,m_seed,sp_mean,\\\n",
    "                 sp_var, h_prop, uid, nsample_o,\\\n",
    "                 Yte_fit, cv_test] = pickle.load(open(fname_o[i], \"rb\"))\n",
    "    out[i] = [i, l, sp_mean,sp_var,  np.mean(cv_test), np.mean(Yte_fit)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rank</th>\n",
       "      <th>lambda</th>\n",
       "      <th>upsilon</th>\n",
       "      <th>llpd</th>\n",
       "      <th>Log-likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, rank, lambda, upsilon, llpd, Log-likelihood]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(out, open('best_model_selected.pkl','wb'))  # save output \n",
    "out = pickle.load(open('best_model_selected.pkl','rb'))\n",
    "outx = pd.DataFrame(out)\n",
    "outx.columns = ['index','rank','lambda', 'upsilon', 'llpd' ,'Log-likelihood']\n",
    "outx.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2280874/3068818150.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the file name and model output from the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_setting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moutx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_setting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfname_o\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vim/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot convert the series to {converter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"__{converter.__name__}__\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot convert the series to <class 'int'>"
     ]
    }
   ],
   "source": [
    "# Get the file name and model output from the best model \n",
    "best_setting = outx[outx.iloc[:,4] == outx.iloc[:,4].max()]\n",
    "i = int(best_setting.loc[:,'index'])\n",
    "fname_o[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rank</th>\n",
       "      <th>lambda</th>\n",
       "      <th>upsilon</th>\n",
       "      <th>llpd</th>\n",
       "      <th>Log-likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.10063</td>\n",
       "      <td>-3.258982</td>\n",
       "      <td>-3.257405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   rank  lambda  upsilon      llpd  Log-likelihood\n",
       "2    2.0  200.0   0.246  0.10063 -3.258982       -3.257405"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Our analysis suggest that MEM with seed 66 is most appropriate with highest full data LLPD.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
